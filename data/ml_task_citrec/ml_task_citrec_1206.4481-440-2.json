{"context": "blackIndeed, HD spaces exhibit non intuitive geometrical\nand statistical properties when compared to lower dimensional\nspaces. Most of them do not behave in a similar way as in three\ndimensional Euclidean spaces (Table\u00a0REF  summarizes\nthe main properties of HD spaces)\u00a0[1]. For\ninstance, samples following a uniform law will have a tendency to\nhave a high concentration in the corners\u00a0[2].\nThe same property holds for normally distributed data: samples tend\nto have a high concentration in the tails\u00a0[3],\nmaking density estimation a difficult task. This problem can be\nrelated to the number of parameters t  to be estimated to fit a\nGaussian distribution which grows quadratically with the space\ndimensionality, t=d(d+3)/2  (5150 for d=100 ). Because of this,\nconventional generative methods are not suitable for analyzing this\ntype of data.\n", "citations": {"[1]": {"id": "https://openalex.org/W2800540439", "ref": "M. G. Kendall, A course in the geometry of n-dimensions. New York: Dover Publication, 1961."}, "[2]": {"id": "https://openalex.org/W2303501228", "ref": "L. Jimenez and D. A. Landgrebe, \u201cSupervised classification in high dimensional space: geometrical, statistical and asymptotical properties of multivariate data,\u201d IEEE Trans. Syst., Man, Cybern. B, vol. 28, pp. 39\u201354, Feb. 1998."}, "[3]": {"id": "https://openalex.org/W7073430", "ref": "J. Herault, A. Guerin-Dugue, and P. Villemain, \u201cSearching for the embedded manifolds in high dimensional data, problems and unsolved questions,\u201d in European Symposium on Artificial Neural Networks, pp. 1\u201312, 2002."}}}