{"context": "The training of a convolutional network requires a large amount of annotated data that provides a rich description of the problem.\nOur work has benefited from the recent publication of two datasets: iSun [1] and SALICON [2].\nThese datasets propose two different approaches for saliency prediction.\nWhile iSun was generated with an eye-tracker to annotate the gaze fixations, the SALICON dataset was built by asking humans to click on the most salient points on the image.\nThe different nature of the saliency maps of the two datasets can be seen in Figure REF .\nThe large size of these datasets has provided for the first time the possibility of training a convnet.\n<FIGURE>", "citations": {"[1]": {"id": "https://openalex.org/W1831674524", "ref": "P. Xu, K. A. Ehinger, Y. Zhang, A. Finkelstein, S. R. Kulkarni, and J. Xiao. Turkergaze: Crowdsourcing saliency with webcam based eye tracking. arXiv preprint arXiv:1504.06755, 2015."}, "[2]": {"id": "https://openalex.org/W1934890906", "ref": "M. Jiang, S. Huang, J. Duan, and Q. Zhao. SALICON: Saliency in context. In Proceedings of the IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), 2015."}}}