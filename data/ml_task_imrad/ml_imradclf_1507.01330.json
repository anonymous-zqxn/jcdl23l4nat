{"year": 2015, "cat": "cs.CV", "smpls": [{"orig_sec": "Introduction", "label": "i", "text": "With the emergence of mobile devices, the amount of user captured and shared images and videos rapidly increases. A huge space for storing and a wide bandwidth for transmitting such data are required if without reducing their file sizes properly. Image and video compression techniques have been designed to reduce the file size meanwhile preserve the visual quality of the frames. JPEG [1], MPEG and H.26x [2], [3] are classic and widely used standards in its history, which employ the block Discrete Cosine Transform (DCT), due to its good energy compaction and decorrelation properties, to achieve the compression. However, an inevitable problem of these standards is that as the compression ratio increases, the fidelity of coded images degrades, i.e. details are ruined and artificial block boundaries appear. The compression artifacts are perceptually annoying, and more importantly, very likely to degenerate the performance of many computer vision algorithms that are primarily designed for uncompressed images or videos, such as image enhancement [4], [5], [6], [7], feature extraction [8], [9], over-segmentation [10], [11], [12] and super-resolution [13], [14]. Hence, the technique for removing or reducing these artifacts is desirable.\n"}, {"orig_sec": "Introduction", "label": "i", "text": "Considering the flexibility to existing codecs makes post-processing approaches attractive, which handle compressed frames at the decoder end, without changing the maturing structure of existing codecs. Mathematically, the compressed image/video sequence C  can be modeled as a linear combination of two components: C=L_I+L_A , where L_I  and L_A  represent the intrinsic layer and the artifact layer, respectively (e.g. Fig. REF ). In the last decades, significant research has been made towards the development of post-processing style deblocking techniques, which can be broadly categorized into two different groups, namely the denoising-style deblocker and the restoration-style one.\n"}, {"orig_sec": "Introduction", "label": "i", "text": "The denoising-style deblockers attempt to suppress the effect of L_A  by (adaptive) local filters. Very first work proposed by Lim and Reeve [1] employs the low pass filter on boundaries, which may also blur intrinsic edges of the image. To address this problem, techniques that adaptively perform filtering on regions obtained by either classification or detection have been proposed [2], [3]. The recent video coding standard, H.264/AVC [4], analyzes artifacts and chooses different filters for different block boundaries according to their local properties. WNNM [5] and (V)BM3D [6] have the same goal of reducing artifacts, although they are originally designed for denoising by utilizing repetitive patterns in the target images or videos. These filtering methods consider the artifacts as noises to be smoothed for visual improvement. However, in general, this kind of deblockers aims at heuristically smoothing visible artifacts without objective criterion, instead of genuinely restoring the original information.\n"}, {"orig_sec": "Introduction", "label": "i", "text": "Alternatively, the restoration-style methods focus on recovering L_I  under some assumptions. Various priors have been exploited [1], [2], [3], [4]. Jung et al. attempt to reconstruct the intrinsic layer via sparse representation, which, however, requires the compression ratio is known and the dictionary is well-learned [6]. Similarly to [6], Choi et al. [7] propose a learning based approach to reduce JPEG artifacts for providing more accurate results in image matting. More recently, Sun and Liu [8] introduce a non-causal temporal prior for video deblocking, which iteratively refines the target frames and the estimation of motion across them. Due to the iterative procedure and the optical flow estimation, the computational load of this approach is very heavy, which limits its applicability. Li et al. [9] develop a four-step method including structure-texture decomposition, scene detail extraction, block artifact reduction and layer recomposition. This approach can produce promising results when the whole or a big part of image with poor texture. In other words, the block artifacts in poor texture regions are well suppressed. Otherwise, its performance sharply degrades. Usually, the recovered results obtained by the restoration-style methods are of better quality than those by the denoising ones. But they are either time consuming and complex (hard to be applied to real world tasks), or case dependent (short of generality).\n"}, {"orig_sec": "Introduction", "label": "i", "text": "As can be seen from the aforementioned methods, the characteristics of the two layers have been well investigated individually, the relationship between the two layers, however, has been rarely studied. In this paper, we show how to decompose the intrinsic and artifact layers for an image or a video sequence by exploiting some strong structural layer priors in both the two layers. The main contributions of this paper can be summarized as follows:\n"}, {"orig_sec": "Introduction", "label": "i", "text": "\nWe propose an effective one-step visual data deblocking method DSLP that harnesses two structural layer priors, i.e. 1) the independence between the gradient fields of the two layers, and 2) the sparsity of the gradient field of the intrinsic layer, in a unified fashion.\n\nWe design a novel Augmented Lagrange Multiplier based algorithm to efficiently and effectively seek the solution of the associated optimization problem. To demonstrate the efficacy and the superior performance of the proposed algorithm over the state-of-the-art alternatives, extensive experiments are conducted.\n\n"}, {"orig_sec": "Experiments", "label": "m", "text": "Parameter Effect.\nOur model involves three free parameters including \u03b1  , \u03b2   and \u03b3  . We here test the effect of each parameter. Although the quality assessment for the task of deblocking is questionable [1], we still employ some to reflect the trend of varying parameters.\nThe most widely used full reference quality assessment might be the peak signal-to-noise ratio (PSNR), which is mathematically simple, but does not correlate well with perceived visual quality. So we do not employ PSNR to quantitatively measure the performance in this paper. Alternatively, the structural similarity (SSIM) metric tries to measure how similar a pair of images are (the deblocked result and its original), which considers three aspects of similarity including luminance, contrast and structure, and thus is more appropriate than PSNR. In addition, we introduce a novel metric called gradient consistency (GC) to corporate with SSIM, which is defined as follows:\nGC(A, B) = \\frac{\u2016 \u2207 A\u2212\u2207 B\u2016 _F\u00b2}{\u220f \u1d62\u208c\u2081\u207fD\u1d62}, \n"}, {"orig_sec": "Experiments", "label": "m", "text": "where A  is the reference and B  the recovered. GC is to see the consistency of gradients of two individuals. Please notice that the higher SSIM the better, while the lower GC the better. Because the dependence of the three parameters is complex, we test them separately. For \u03b1  , we fix \u03b2   and \u03b3   to 30 and 6, respectively. As can be viewed in Fig. REF , the best \u03b1   values change from 0.6\u223c 0.7  for the case with JPEG quality 10 to 0.2\u223c 0.3  for the case with JPEG quality 20 in terms of both SSIM and GC. This result is consistent with the fact that more artifacts require more powerful smoother to eliminate. As for \u03b2  , we can observe from the second row of Fig. REF  that it performs stably in the range [15,100]  for JPEG quality 10 and [5,100]  for JPEG quality 20, respectively. Similarly, the parameter \u03b3   can achieve high performance when it is set to a relatively large value for both the two cases shown in Fig. REF . For the rest experiments, we will fix \u03b2   and \u03b3   to 30 and 6, respectively.\n<FIGURE><FIGURE>"}, {"orig_sec": "Experiments", "label": "m", "text": "Convergence Speed. Figure REF  displays the convergence speed of the proposed Algorithm REF , without loss of generality, on the image shown in Fig. REF , in which the stop criterion sharply drops to the level of 10\u207b\u2075  with about 30 iterations and to 10\u207b\u2077  with 70 iterations. We also show four pairs of the separated layers at 3, 5, 30 and 70 iterations. We see that the results at 30 iterations is very close to those at 70.\n"}, {"orig_sec": "Experiments", "label": "m", "text": "Relationship to TV model.\nFrom the objective function (REF ), we can observe that our model can reduce to the anisotropic Total Variation (TV) model by disabling the third and fourth terms, say the gradient independence prior. To demonstrate the benefit of the gradient independence prior, we conduct a comparison between TV and our method. To better view the difference, we do not introduce artifacts into the testing. As shown in Fig. REF , bigger \u03b1   leads to more details smoothed for both TV and DSLP. The difference is that, in terms of visual quality, TV smooths both the high-frequency and low-frequency information, while our DSLP eliminates weak textures but keeps dominant edges. Quantitatively, when setting \u03b1   to 1.0, DSLP achieves 0.6302  SSIM and 80.41  GC, which are much better than those of TV, i.e. 0.4467  SSIM and 217.45  GC. The results of \u03b1 =0.5  are analogue. Please note that even increasing \u03b1   to 1.5 , DSLP still can provide very promising result. From the viewpoint of artifact, we further give an example shown in Fig. REF  to see the power of the independence prior. For better view, we amplify the artifact to 10 times of it. As can be seen, TV greatly filters textures with very high false positive ratio (the details of bird body), while DSLP mainly focuses on the block artifacts. The above experimental results reveal the relationship and the difference between TV and DSLP, and demonstrate the advance of DSLP.\n<FIGURE><FIGURE>"}, {"orig_sec": "Experiments", "label": "m", "text": "IDSLP: Improved DSLP. Let us here revisit the complication of JPEG compression in terms of visual quality. As can be viewed in the first image of Fig. REF  (JPEG Quality 10), there are actually two main issues, say the staircase effect around block boundaries as well as the serration along image edges. The denoising techniques like BM3D [1] can reduce the serration in the frame, but hardly deal with the staircase effect, as shown in the second picture of Fig. REF  (setting \u03c3 =50 ). As for DSLP, it is good at cleaning the staircase around block boundaries but leaves the serration (see the third picture in Fig. REF , setting \u03b1 =0.6 ). Intuitively, we can further improve the visual quality by making use of their respective advantages. The most right result in Fig. REF  demonstrates the effectiveness of such a strategy, which is obtained by firstly executing the denoising technology (in this paper we adopt BM3D, \u03c3 =25 ) and then applying DSLP on the denoised version (\u03b1 = 0.3 ).\n<FIGURE><FIGURE>"}, {"orig_sec": "Experiments", "label": "m", "text": "Image Deblocking. In this part, we evaluate the performance of our method on image deblocking, compared with the state-of-the art alternatives including a reconstruction based method using Field of Experts (FoE) [1], a local filtering based method via Shape Adaptive DCT (SADCT) [2], a layer decomposition based method for JPEG Artifact Suppression (JAS) [3], a denoising based method BM3D [4], a Total Variation regularized restoration method (TV) [5], and our proposed DSLP and IDSLP. The codes for the competitors are either downloaded from the authors' websites or provided by the authors, their parameters are tuned or set as suggested by the authors for obtaining their best possible results. As for DSLP on image deblocking, only spatial gradients are taken into account, say \u2207 \\mathrel {\\mathop :}={ \u2207 \u2081,\u2207 \u2082}  . In addition, all the codes are implemented in Matlab, which assures the fairness of time cost comparison. We provide the quantitative (SSIM, GC and Time) and qualitative results on several images in Fig. REF , which are compressed by JPEG with quality 10. As can be seen from Fig. REF , FoE, SADCT, JAS and BM3D can only slightly suppress but not thoroughly eliminate the staircase effect under such a compression rate. DSLP is able to eliminate or largely reduce the staircase, while IDSLP can further mitigate the effect of edge serration. In terms of computational cost, DSLP is superior to SADCT and FoE, and competitive with JAS and TV, but inferior to BM3D. Moreover, IDSLP integrates the denoising and deblocking components, and thus its time cost sums up those of BM3D (for this paper) and DSLP.\nDue to the limited space and the nature of the deblocking problem, so please see the supplementary material for larger and more results, which are best viewed in original sizes.\n"}, {"orig_sec": "Experiments", "label": "m", "text": "Video Deblocking. For this task, we test both spatial only gradients \u2207 \\mathrel {\\mathop :}={ \u2207 \u2081,\u2207 \u2082}   and spatial-temporal gradients \u2207 \\mathrel {\\mathop :}={ \u2207 \u2081,\u2207 \u2082, \u2207 \u2083}   for (I)DSLP, which are denoted as (I)DSLP and (I)VDSLP, respectively. This comparison involves VBM3D that is a video extension of BM3D, DSLP, IDSLP and IVDSLP.Another related video deblocking method is [2], but its code is not available when this paper is prepared. Therefore, we do not compare with it. Moreover, with regard to time cost, as the authors of [2] stated, their C++ implementation takes about 3 hours to process 32 frame 640\u00d7 480  sequence, which significantly limits its applicability. From Fig. REF , we can see that the problem for BM3D on image deblocking still exists for VBM3D on video deblocking. In other words, the staircase remains (see yellow arrows). DSLP significantly reduces the staircase effect, while IDSLP and IVDSLP further take care of the serration. We note that, compared with IDSLP, IVDSLP slightly excludes some textures (e.g. the leaves on the top-right corner, white arrows). This is because the temporal gradient is enforced to be sparse, which would be more helpful for videos with slow motions, but over-smooth the content of videos with sudden or fast motions. More video results can be found in the supplementary.\n"}, {"orig_sec": "Conclusion", "label": "d", "text": "Artifact separation from images or video sequences is an important, yet severely ill-posed problem. To overcome its difficulty, this paper has shown how to harness two prior structures of the intrinsic and artifact layers, including the gradient sparsity of the intrinsic layer and the gradient independence between the two components, to make the problem well-defined and feasible to solve. We have formulated the problem in a unified optimization framework and proposed an efficient algorithm to find the optimal solution. The experimental results, compared to the state of the arts, have demonstrated the clear advantages of the proposed method in terms of visual quality and simplicity, which can be used for many advanced image/video processing tasks.\n"}]}